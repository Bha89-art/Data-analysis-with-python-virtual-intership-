{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06798b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bad74817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('hearts.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0dfda37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
      "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
      "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
      "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
      "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
      "\n",
      "   ca  thal  target  risk_factor_count  \n",
      "0   2     3       0                  0  \n",
      "1   0     3       0                  2  \n",
      "2   0     3       0                  1  \n",
      "3   1     3       0                  0  \n",
      "4   3     2       0                  1  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows to ensure the data is loaded correctly\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04d00b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age age_group  fbs  exang  risk_factor_count\n",
      "0   52     50-60    0      0                  0\n",
      "1   53     50-60    1      1                  2\n",
      "2   70     60-70    0      1                  1\n",
      "3   61     60-70    0      0                  0\n",
      "4   62     60-70    1      0                  1\n"
     ]
    }
   ],
   "source": [
    "# Generate new features\n",
    "# Age Grouping\n",
    "data['age_group'] = pd.cut(data['age'], bins=[0, 40, 50, 60, 70, 100], labels=['<40', '40-50', '50-60', '60-70', '>70'])\n",
    "\n",
    "# Calculate risk factor count from 'fbs' and 'exang'\n",
    "data['risk_factor_count'] = data[['fbs', 'exang']].sum(axis=1)\n",
    "\n",
    "# Confirm the new features are created\n",
    "print(data[['age', 'age_group', 'fbs', 'exang', 'risk_factor_count']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97529496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical features to numerical using one-hot encoding\n",
    "data = pd.get_dummies(data, columns=['age_group', 'cp', 'restecg', 'slope', 'thal'], drop_first=True)\n",
    "\n",
    "# Prepare the data for modeling\n",
    "X = data.drop(['target'], axis=1)\n",
    "y = data['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaaf05e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# PCA for dimensionality reduction (optional step for visualizing importance of features)\n",
    "pca = PCA(n_components=5)\n",
    "X_pca = pca.fit_transform(X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73503610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Feature  Importance\n",
      "8                  ca    0.117200\n",
      "5             thalach    0.106101\n",
      "7             oldpeak    0.098033\n",
      "22             thal_2    0.077613\n",
      "0                 age    0.077420\n",
      "23             thal_3    0.074365\n",
      "3                chol    0.067359\n",
      "2            trestbps    0.067018\n",
      "6               exang    0.057745\n",
      "20            slope_2    0.035743\n",
      "15               cp_2    0.034819\n",
      "1                 sex    0.030488\n",
      "9   risk_factor_count    0.028622\n",
      "19            slope_1    0.027480\n",
      "17          restecg_1    0.019487\n",
      "16               cp_3    0.016033\n",
      "14               cp_1    0.015083\n",
      "11    age_group_50-60    0.011823\n",
      "12    age_group_60-70    0.011593\n",
      "10    age_group_40-50    0.009431\n",
      "4                 fbs    0.006405\n",
      "21             thal_1    0.006143\n",
      "13      age_group_>70    0.003052\n",
      "18          restecg_2    0.000943\n"
     ]
    }
   ],
   "source": [
    "# Feature importance using Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X, y)\n",
    "importances = rf.feature_importances_\n",
    "feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': importances}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display feature importance\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c9302db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting important features (based on an arbitrary threshold)\n",
    "important_features = feature_importance[feature_importance['Importance'] > 0.05]['Feature']\n",
    "X_important = data[important_features]\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_important, y, test_size=0.3, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2bb4ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9902597402597403\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc4353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
